<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Dense Depth Priors for Neural Radiance Fields from Sparse Input Views</title>
    <link rel="stylesheet" href="w3.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
</head>

<body>

<br/>
<br/>

<div class="w3-container" id="paper">
    <div class="w3-content" style="max-width:850px">
  
    <h2 align="center" id="title1"><b>Dense Depth Priors for Neural Radiance Fields</b></h2>
    <h2 align="center" id="title2"><b>from Sparse Input Views</b></h2>
    <br/>

    <p align="center" id="title3">arXiv 2021</p>

    <p align="center" class="center_text" id="authors">
        <a target="_blank" href="http://www.niessnerlab.org/members/barbara_roessle/profile.html">Barbara Roessle</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://jonbarron.info/">Jonathan T. Barron</a><sup>2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://bmild.github.io/">Ben Mildenhall</a><sup>2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a><sup>2</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://www.niessnerlab.org/members/matthias_niessner/profile.html">Matthias Nie&szlig;ner</a><sup>1</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
    </p>

    <p class="center_text" align="center">
        <sup>1</sup>Technical University of Munich
        &nbsp;&nbsp;&nbsp;&nbsp;
        <sup>2</sup>Google Research
    </p>

    <p>
        <img src="teaser.svg" alt="teaser" height="100%" width="100%" >
    <p/>

    <h3 class="w3-left-align" id="intro"><b>Introduction</b></h3>
    <p>
        Neural radiance fields (NeRF) encode a scene into a neural representation that enables photo-realistic rendering of novel views. 
        However, a successful reconstruction from RGB images requires a large number of input views taken under static conditions &mdash; typically up to a few hundred images for room-size scenes. 
        Our method aims to synthesize novel views of whole rooms from an order of magnitude fewer images. 
        To this end, we leverage dense depth priors in order to constrain the NeRF optimization.
        First, we take advantage of the sparse depth data that is freely available from the structure from motion (SfM) preprocessing step used to estimate camera poses.
        Second, we use depth completion to convert these sparse points into dense depth maps and uncertainty estimates, which are used to guide NeRF optimization.
        Our method enables data-efficient novel view synthesis on challenging indoor scenes, using as few as 18 images for an entire scene.
    </p>

    <h3 class="w3-left-align" id="video"><b>Video</b></h3>
    <p>
    <iframe width="850" height="480" src="https://www.youtube.com/embed/zzkvvdcvksc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <p/>

    <h3 class="w3-left-align" id="publication"><b>Publication</b></h3>
    <a href="https://arxiv.org/pdf/2112.03288.pdf" target="__blank">Paper</a> | <a href="https://arxiv.org/abs/2112.03288" target="__blank">arXiv</a> | <span style="color:grey;">Code</span>
    <center>
        <a href="" target="__blank"><img src="paper_preview.jpg" style="max-width:100%" /></a>
    </center><br>

    If you find our project useful, please consider citing us:
    <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 11px">
@article{roessle2021depthpriorsnerf,
    title={Dense Depth Priors for Neural Radiance Fields from Sparse Input Views},
    author={Barbara Roessle and Jonathan T. Barron and Ben Mildenhall and Pratul P. Srinivasan and Matthias Nie{\ss}ner},
    archivePrefix={arXiv},
    year={2021}
}
</pre>

    </div>

</div>

<br/>
<br/>

</body>
</html>
